---
layout: post
title:  Convolutional Neural Network (CNN)
---


In this post, we will learn several new skills and concepts related to image classification in Tensorflow. The Method we use to do image classification is called **Convolutional Neural Network** (CNN). I will give an breif introduction of Convolutional Neural Network and how it works in detail. Then, I will show you how to apply Convolutional Neural Network in TensorFlow.

## (A). Load Packages and Obtain Data

First, we are going to import all the libraries we need.
```python
import os
import tensorflow as tf 
from tensorflow.keras import utils, layers
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, InputLayer, ReLU, Softmax, RandomFlip, RandomRotation, Rescaling
```
<br />

**Then, we are going to load our data.**
```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```
<br />

**Then we are going to rapidly read the data.**
```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

### I. Working with Datasets

Write a function to create a two-row visualization. In the first row, show three random pictures of cats. In the second row, show three random pictures of dogs.
```python
def show_images():
    plt.figure(figsize=(10, 10))
    class_names = ["cat", "dog"]
    for images, labels in train_dataset.take(1):
        cat = 0
        dog = 0
        for i in range(32):
            if labels[i] == 0 and cat < 3:
                ax = plt.subplot(2, 3, cat + 1)
                plt.imshow(images[i].numpy().astype("uint8"))
                plt.title(class_names[labels[i]])
                plt.axis("off")
                cat += 1
            elif class_names[labels[i]] == "dog" and dog < 3:
                ax = plt.subplot(2, 3, dog + 4)
                plt.imshow(images[i].numpy().astype("uint8"))
                plt.title(class_names[labels[i]])
                plt.axis("off")
                dog += 1

show_images()
```

![dogcat.jpg]({{ site.baseurl }}/images/dogcat.png)


### II. Check Label Frequencies

Compute the number of images in the training data with label 0 (corresponding to "cat") and label 1 (corresponding to "dog").
```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
sum(labels_iterator)
```
```
1000
```

We get 1000, because label 0 equal to "cat" and label 1 equal to "dog". So, 1000 means there are 1000 dogs in total. And the rest are cats.


## (B). First Model

*Create a tf.keras.Sequential model using some of the layers. In this model, it includes two Conv2D layers, two MaxPooling2D layers, one Flatten layer,one Dense layer, and one Dropout layer.*
```python
model1 = tf.keras.models.Sequential([
    layers.Conv2D(32, 9, activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, 6, activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dropout(0.3),
    layers.Dense(1, activation="sigmoid")
])
model1.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```
Epoch 1/20
63/63 [==============================] - 7s 90ms/step - loss: 11.3891 - accuracy: 0.5065 - val_loss: 0.6907 - val_accuracy: 0.5594
Epoch 2/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6879 - accuracy: 0.5300 - val_loss: 0.6927 - val_accuracy: 0.5693
Epoch 3/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6868 - accuracy: 0.5330 - val_loss: 0.6912 - val_accuracy: 0.5606
Epoch 4/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6778 - accuracy: 0.5540 - val_loss: 0.6844 - val_accuracy: 0.5644
Epoch 5/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6679 - accuracy: 0.5525 - val_loss: 0.7312 - val_accuracy: 0.5483
Epoch 6/20
63/63 [==============================] - 6s 89ms/step - loss: 0.6567 - accuracy: 0.5620 - val_loss: 0.6797 - val_accuracy: 0.5606
Epoch 7/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6402 - accuracy: 0.5830 - val_loss: 0.6881 - val_accuracy: 0.5866
Epoch 8/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6489 - accuracy: 0.5955 - val_loss: 0.7219 - val_accuracy: 0.5656
Epoch 9/20
63/63 [==============================] - 6s 88ms/step - loss: 0.6190 - accuracy: 0.6040 - val_loss: 0.8278 - val_accuracy: 0.5495
Epoch 10/20
63/63 [==============================] - 6s 87ms/step - loss: 0.6090 - accuracy: 0.6155 - val_loss: 0.8075 - val_accuracy: 0.5520
Epoch 11/20
63/63 [==============================] - 7s 104ms/step - loss: 0.5614 - accuracy: 0.6555 - val_loss: 0.7720 - val_accuracy: 0.5309
Epoch 12/20
63/63 [==============================] - 6s 87ms/step - loss: 0.5287 - accuracy: 0.6895 - val_loss: 0.9617 - val_accuracy: 0.5371
Epoch 13/20
63/63 [==============================] - 6s 88ms/step - loss: 0.4937 - accuracy: 0.7215 - val_loss: 0.8997 - val_accuracy: 0.5953
Epoch 14/20
63/63 [==============================] - 6s 88ms/step - loss: 0.4869 - accuracy: 0.7615 - val_loss: 0.9904 - val_accuracy: 0.6188
Epoch 15/20
63/63 [==============================] - 6s 87ms/step - loss: 0.4426 - accuracy: 0.7800 - val_loss: 1.0335 - val_accuracy: 0.5928
Epoch 16/20
63/63 [==============================] - 6s 88ms/step - loss: 0.4230 - accuracy: 0.7895 - val_loss: 1.2472 - val_accuracy: 0.5903
Epoch 17/20
63/63 [==============================] - 6s 88ms/step - loss: 0.4100 - accuracy: 0.7980 - val_loss: 1.4335 - val_accuracy: 0.6064
Epoch 18/20
63/63 [==============================] - 6s 87ms/step - loss: 0.3853 - accuracy: 0.8000 - val_loss: 1.3257 - val_accuracy: 0.5842
Epoch 19/20
63/63 [==============================] - 6s 88ms/step - loss: 0.4080 - accuracy: 0.7975 - val_loss: 1.5859 - val_accuracy: 0.5780
Epoch 20/20
63/63 [==============================] - 6s 88ms/step - loss: 0.3698 - accuracy: 0.8275 - val_loss: 1.4143 - val_accuracy: 0.6188
```

Train your model and plot the history of the accuracy on both the training and validation sets. 
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![model1.jpg]({{ site.baseurl }}/images/model1.png)

>1. *the validation accuracy of my model stabilized between **53% and 62%** during training.*
>2. The highest validation accuracy is 61.88%. Compare that to the baseline, I improved 9% of accuracy.
>3. After we drew the line, I observed overfitting in model1.


## (C). Model 2: Model with Data Augmentation

*Now we’re going to add some data augmentation layers to your model. Data augmentation refers to the practice of including modified copies of the same image in the training set. For example, a picture of a cat is still a picture of a cat even if we flip it upside down or rotate it 90 degrees. We can include such transformed versions of the image in our training process in order to help our model learn so-called invariant features of our input images.*
```python
flipper = tf.keras.Sequential([
    RandomFlip("vertical")
])
rotater = tf.keras.Sequential([
    tf.keras.layers.RandomRotation(0.1),    
])


for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    # In the first three rows we perform random flips 
    for i in range(6):
      if i < 3:
        ax = plt.subplot(2, 3, i + 1)
        augmented_image = flipper(tf.expand_dims(image[0], 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
      else:
        ax = plt.subplot(2, 3, i + 1)
        augmented_image = rotater(tf.expand_dims(image[0], 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
```


![trans_dogcat.jpg]({{ site.baseurl }}/images/trans_dogcat.png)


Create a new tf.keras.models.Sequential model called model2 in which the first two layers are augmentation layers and train our model
```python
model2 = tf.keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.2),

    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dropout(.2),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])

model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```
Epoch 1/20
63/63 [==============================] - 7s 91ms/step - loss: 38.2192 - accuracy: 0.4985 - val_loss: 0.6975 - val_accuracy: 0.4901
Epoch 2/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6991 - accuracy: 0.5245 - val_loss: 0.6829 - val_accuracy: 0.5408
Epoch 3/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6889 - accuracy: 0.5465 - val_loss: 0.6863 - val_accuracy: 0.5495
Epoch 4/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6921 - accuracy: 0.5485 - val_loss: 0.6911 - val_accuracy: 0.5210
Epoch 5/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6872 - accuracy: 0.5330 - val_loss: 0.6928 - val_accuracy: 0.5260
Epoch 6/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6854 - accuracy: 0.5455 - val_loss: 0.6910 - val_accuracy: 0.5347
Epoch 7/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6837 - accuracy: 0.5560 - val_loss: 0.6917 - val_accuracy: 0.5124
Epoch 8/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6838 - accuracy: 0.5545 - val_loss: 0.7033 - val_accuracy: 0.5371
Epoch 9/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6719 - accuracy: 0.5905 - val_loss: 0.7069 - val_accuracy: 0.5557
Epoch 10/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6776 - accuracy: 0.5880 - val_loss: 0.7052 - val_accuracy: 0.5631
Epoch 11/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6729 - accuracy: 0.5785 - val_loss: 0.7116 - val_accuracy: 0.5458
Epoch 12/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6751 - accuracy: 0.5810 - val_loss: 0.7024 - val_accuracy: 0.5483
Epoch 13/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6720 - accuracy: 0.5875 - val_loss: 0.6982 - val_accuracy: 0.5582
Epoch 14/20
63/63 [==============================] - 6s 83ms/step - loss: 0.6684 - accuracy: 0.6010 - val_loss: 0.6979 - val_accuracy: 0.5557
Epoch 15/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6754 - accuracy: 0.5970 - val_loss: 0.7067 - val_accuracy: 0.5495
Epoch 16/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6632 - accuracy: 0.6035 - val_loss: 0.7031 - val_accuracy: 0.5804
Epoch 17/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6586 - accuracy: 0.6015 - val_loss: 0.7133 - val_accuracy: 0.5916
Epoch 18/20
63/63 [==============================] - 5s 82ms/step - loss: 0.6639 - accuracy: 0.6060 - val_loss: 0.6976 - val_accuracy: 0.5681
Epoch 19/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6613 - accuracy: 0.5920 - val_loss: 0.7089 - val_accuracy: 0.5619
Epoch 20/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6665 - accuracy: 0.6030 - val_loss: 0.7026 - val_accuracy: 0.5953
```

Visualize the training history.
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```
![model2.jpg]({{ site.baseurl }}/images/model2.png)


>1. *the validation accuracy of my model stabilized between **49% and 60%** during training.*
>2. The highest validation accuracy is 59.53%. Compare that to the model 1, it's a little bit worse. But not too much.
>3. After we drew the line, the two line matches better than model 1, so I didn't observed overfitting in model2.


## (D). Model 3: Data Preprocessing
*Sometimes, it can be helpful to make simple transformations to the input data. For example, in this case, the original data has pixels with RGB values between 0 and 255, but many models will train faster with RGB values normalized between 0 and 1, or possibly between -1 and 1. These are mathematically identical situations, since we can always just scale the weights. But if we handle the scaling prior to the training process, we can spend more of our training energy handling actual signal in the data and less energy having the weights adjust to the data scale.*

We are going to create a preprocessing layer called preprocessor which we can slot into our model pipeline.
```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Create a new tf.keras.models.Sequential model called model3 and train our model
```python
model3 = tf.keras.Sequential([
    preprocessor,
    
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.2),

    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dropout(.2),
    layers.Dense(64, activation='relu'),
    layers.Dense(2),
])

model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```
Epoch 1/20
63/63 [==============================] - 7s 79ms/step - loss: 0.7903 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.4963
Epoch 2/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5012
Epoch 3/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4889
Epoch 4/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4889
Epoch 5/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6823 - accuracy: 0.5240 - val_loss: 0.6622 - val_accuracy: 0.6027
Epoch 6/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6693 - accuracy: 0.5780 - val_loss: 0.6420 - val_accuracy: 0.6225
Epoch 7/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6531 - accuracy: 0.6120 - val_loss: 0.6340 - val_accuracy: 0.6547
Epoch 8/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6446 - accuracy: 0.6270 - val_loss: 0.6297 - val_accuracy: 0.6535
Epoch 9/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6438 - accuracy: 0.6175 - val_loss: 0.6332 - val_accuracy: 0.6473
Epoch 10/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6287 - accuracy: 0.6425 - val_loss: 0.6239 - val_accuracy: 0.6436
Epoch 11/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6253 - accuracy: 0.6580 - val_loss: 0.6134 - val_accuracy: 0.6683
Epoch 12/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6035 - accuracy: 0.6830 - val_loss: 0.5997 - val_accuracy: 0.6856
Epoch 13/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5995 - accuracy: 0.6715 - val_loss: 0.6231 - val_accuracy: 0.6510
Epoch 14/20
63/63 [==============================] - 5s 76ms/step - loss: 0.5980 - accuracy: 0.6810 - val_loss: 0.5976 - val_accuracy: 0.6807
Epoch 15/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5914 - accuracy: 0.6975 - val_loss: 0.5895 - val_accuracy: 0.6795
Epoch 16/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5852 - accuracy: 0.6885 - val_loss: 0.5642 - val_accuracy: 0.7240
Epoch 17/20
63/63 [==============================] - 5s 76ms/step - loss: 0.5638 - accuracy: 0.7195 - val_loss: 0.5640 - val_accuracy: 0.7092
Epoch 18/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5616 - accuracy: 0.7205 - val_loss: 0.5671 - val_accuracy: 0.7129
Epoch 19/20
63/63 [==============================] - 5s 78ms/step - loss: 0.5522 - accuracy: 0.7325 - val_loss: 0.5794 - val_accuracy: 0.7054
Epoch 20/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5553 - accuracy: 0.7255 - val_loss: 0.5594 - val_accuracy: 0.6918
```

Visualize the training history.
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![model3.jpg]({{ site.baseurl }}/images/model3.png)


>1. *the validation accuracy of my model stabilized between **49% and 72%** during training.*
>2. The highest validation accuracy is 72.40%. Compare that to the model 1, it's much better now.
>3. After we drew the line, I didn't observed any overfitting in model3.


## (E). Model 4: Transfer Learning
*So far, we’ve been training models for distinguishing between cats and dogs from scratch. In some cases, however, someone might already have trained a model that does a related task, and might have learned some relevant patterns. For example, folks train machine learning models for a variety of image recognition tasks. Maybe we could use a pre-existing model for our task?*

To do this, we need to first access a pre-existing “base model”, incorporate it into a full model for our current task, and then train that model.

We are going to download MobileNetV2 and configure it as a layer that can be included in our model.
```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Now, create a model called model4 that uses MobileNetV2 and train the model.
```python
model4 = tf.keras.Sequential([
    preprocessor,
    RandomFlip('horizontal'),
    RandomRotation(0.2),     

    base_model_layer,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.3),
    layers.Dense(1, activation="sigmoid") 
])

model4.compile(optimizer=tf.keras.optimizers.Adam(0.0001),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```
Epoch 1/20
63/63 [==============================] - 12s 123ms/step - loss: 0.5886 - accuracy: 0.6870 - val_loss: 0.4352 - val_accuracy: 0.8255
Epoch 2/20
63/63 [==============================] - 6s 86ms/step - loss: 0.4407 - accuracy: 0.8040 - val_loss: 0.3286 - val_accuracy: 0.8849
Epoch 3/20
63/63 [==============================] - 6s 87ms/step - loss: 0.3766 - accuracy: 0.8440 - val_loss: 0.2680 - val_accuracy: 0.9233
Epoch 4/20
63/63 [==============================] - 6s 87ms/step - loss: 0.3212 - accuracy: 0.8755 - val_loss: 0.2251 - val_accuracy: 0.9344
Epoch 5/20
63/63 [==============================] - 6s 86ms/step - loss: 0.2881 - accuracy: 0.8815 - val_loss: 0.1897 - val_accuracy: 0.9468
Epoch 6/20
63/63 [==============================] - 6s 86ms/step - loss: 0.2580 - accuracy: 0.9050 - val_loss: 0.1773 - val_accuracy: 0.9493
Epoch 7/20
63/63 [==============================] - 6s 87ms/step - loss: 0.2449 - accuracy: 0.9000 - val_loss: 0.1607 - val_accuracy: 0.9592
Epoch 8/20
63/63 [==============================] - 7s 99ms/step - loss: 0.2340 - accuracy: 0.9080 - val_loss: 0.1409 - val_accuracy: 0.9691
Epoch 9/20
63/63 [==============================] - 8s 126ms/step - loss: 0.2264 - accuracy: 0.9145 - val_loss: 0.1385 - val_accuracy: 0.9653
Epoch 10/20
63/63 [==============================] - 6s 87ms/step - loss: 0.1932 - accuracy: 0.9340 - val_loss: 0.1191 - val_accuracy: 0.9752
Epoch 11/20
63/63 [==============================] - 6s 85ms/step - loss: 0.2089 - accuracy: 0.9180 - val_loss: 0.1199 - val_accuracy: 0.9715
Epoch 12/20
63/63 [==============================] - 6s 86ms/step - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.1111 - val_accuracy: 0.9752
Epoch 13/20
63/63 [==============================] - 6s 85ms/step - loss: 0.1910 - accuracy: 0.9250 - val_loss: 0.1057 - val_accuracy: 0.9765
Epoch 14/20
63/63 [==============================] - 6s 87ms/step - loss: 0.1730 - accuracy: 0.9350 - val_loss: 0.1012 - val_accuracy: 0.9752
Epoch 15/20
63/63 [==============================] - 6s 87ms/step - loss: 0.1802 - accuracy: 0.9285 - val_loss: 0.1014 - val_accuracy: 0.9765
Epoch 16/20
63/63 [==============================] - 6s 87ms/step - loss: 0.1746 - accuracy: 0.9315 - val_loss: 0.0997 - val_accuracy: 0.9752
Epoch 17/20
63/63 [==============================] - 6s 86ms/step - loss: 0.1744 - accuracy: 0.9270 - val_loss: 0.0933 - val_accuracy: 0.9765
Epoch 18/20
63/63 [==============================] - 6s 87ms/step - loss: 0.1718 - accuracy: 0.9360 - val_loss: 0.0873 - val_accuracy: 0.9752
Epoch 19/20
63/63 [==============================] - 6s 86ms/step - loss: 0.1738 - accuracy: 0.9335 - val_loss: 0.0873 - val_accuracy: 0.9765
Epoch 20/20
63/63 [==============================] - 6s 86ms/step - loss: 0.1600 - accuracy: 0.9410 - val_loss: 0.0832 - val_accuracy: 0.9765
```

Visualize the training history.
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![model4.jpg]({{ site.baseurl }}/images/model4.png)

>1. *the validation accuracy of my model stabilized between **83% and 98%** during training.*
>2. The highest validation accuracy is 97.65%. Compare that to the model 1, it's much better now.
>3. After we drew the line, I didn't observed any overfitting in model4.


## (F). Score on Test Data

Finally, evaluate the accuracy of your most performant model on the unseen test_dataset.
```python
loss, accuracy = model4.evaluate(test_dataset)
print('Test accuracy :', accuracy)
```
```
6/6 [==============================] - 1s 83ms/step - loss: 0.0651 - accuracy: 0.9896
Test accuracy : 0.9895833134651184
```

The accuracy of test data is 98.95%.


<br />

<br />

<br />