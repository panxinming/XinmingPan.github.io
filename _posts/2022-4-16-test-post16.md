---
layout: post
title:  Convolutional Neural Network (CNN)
---

In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of artificial neural network, most commonly applied to analyze visual imagery. It has applications in image and video recognition, recommender systems, image classification, image segmentation, medical image analysis, natural language processing and so on.

The image classification problem is the problem of assigning a label to an image. For example, we might want to assign the label "duck" to pictures of ducks, the label "frog" to pictures of frogs, and so on. 

Here, I will introduce some of the most important tools for image classification: **convolutional neural networks**.

```python
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
```


## Getting Data

we'll use a subset of the [CIFAR-10 data set](https://www.cs.toronto.edu/~kriz/cifar.html). This data set can be conveniently accessed using a method from `tensorflow.keras.datasets`:

```python
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
```

There are 50,000 training images and 10,000 test images. Each image has **32x32** pixels, and there are three color "channels" -- **red**, **green**, and **blue**.

```python
train_images.shape, test_images.shape
```
```
((50000, 32, 32, 3), (10000, 32, 32, 3))
```

There are **10** classes of image, encoded by the labels arrays.

<br>

```python
train_labels[0:5]
```
```
array([[6],
       [9],
       [9],
       [4],
       [1]], dtype=uint8)
```

Each class corresponds to a type of object, so let's give them names.

```python
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']
```

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()
```

![]({{ site.baseurl }}/images/cnn1.png)



## Convolution

Convolution is a mathematical operation commonly used to extract **features** (meaningful properties) from images. The idea of image convolution is pretty simple. We define a **kernel** matrix containing some numbers, and we "slide it over" the input data. At each location, we multiply the data values by the kernel matrix values, and add them together. Here's an illustrative diagram:

![]({{ site.baseurl }}/images/cnn2.jpg)

<br>

![](https://d2l.ai/_images/correlation.svg)

The value of 19 in the output is obtained in this example by computing $$0 \times 0 + 1 \times 1 + 3 \times 2 + 4 \times 3 = 19$$. 

This operation might seem either abstract or trivial, but it can be used to extract useful image features. For example, let's manually define a kernel and use it to perform "edge detection" in a greyscale image. 


```python
im = train_images[9,:,:,0] 
# this one's a cat, only taking the "blue" channel for convenience. Recall that we have blue, red and green channel.
plt.imshow(im, cmap = "gray")
plt.show()
```
![]({{ site.baseurl }}/images/cnn3.png)

<br>

Let's create a random kernel.
```python
kernel = np.array([[-1, -1, -1], 
                   [-1,  8, -1], 
                   [-1, -1, -1]])
```


Convolutional Layer is to figure out the boundary of one image. Observe that the convolved image (right) has darker patches corresponding to the distinct "edges" in the image, where darker colors meet lighter colors. 
```python
from scipy.signal import convolve2d
# Compute the gradient of an image by 2D convolution
convd = convolve2d(im, kernel, mode = "same")
fig, axarr = plt.subplots(1, 2)
axarr[0].imshow(im, cmap = "gray")
axarr[1].imshow(convd, cmap = "gray", vmin = 0, vmax = 1)
plt.show()
```

![]({{ site.baseurl }}/images/cnn4.png)


## Learning Kernels

There are lots of convolutional kernels we could potentially use. How do we know which ones are meaningful? In practice, we don't. So, we treat them as parameters, and learn them from data as part of the model fitting process. This is exactly what the `Conv2d` layer allows us to do. 


```python
# create a layer which has 32 numbers of output
# 3 \times 3 size kernal
# And the Activation function to use, we usually use relu function.
conv = layers.Conv2D(32, (3, 3), 
                     activation='relu', 
                     input_shape=(32, 32, 3),
                     dtype = "float64")
```

```python
# pick an individual image while preserving dimensions
color_im = train_images[9:10]

# perform convolution and extract as numpy array
# Now our image after convolution has 32 features, because in last step we define our output as 32.
convd = conv(color_im).numpy()

# get a single feature (corresponding to one choice of convolution)
feature = convd[0,:,:,0]

plt.imshow(feature, cmap = "gray")
plt.gca().axis("off")
```

![]({{ site.baseurl }}/images/cnn5.png)



Let's compare a few other possibilities:
```python
fig, axarr = plt.subplots(3, 3, figsize = (8, 6))

axarr[0, 0].imshow(color_im[0])
axarr[0,0].axis("off")
axarr[0,0].set(title = "Original")

i = 0
# compare 9 features to see which is the best.
for ax in axarr.flatten()[1:]:
    ax.imshow(convd[0,:,:,i], cmap = "gray")
    i += 1
    ax.axis("off")
    ax.set(title = "Feature " + str(i))
    
plt.tight_layout()
```

![]({{ site.baseurl }}/images/cnn6.png)

These features may or may not be informative -- they are purely random! We can try to learn informative features by embedding these kernels in a model and optimizing. 